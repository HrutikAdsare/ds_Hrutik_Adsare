{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF4JuaTmeCso",
        "outputId": "c26b8274-1786-4985-dfde-f2412fd83e24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Fear & Greed: (2644, 4)\n",
            "Trades: (211224, 16)\n",
            "Engineered dataset: (211096, 23)\n",
            "Train / Valid sizes: (168876, 17) (42220, 17)\n",
            "[LightGBM] [Info] Number of positive: 71139, number of negative: 97737\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006956 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3279\n",
            "[LightGBM] [Info] Number of data points in the train set: 168876, number of used features: 17\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "           model  best_threshold  accuracy        f1  precision    recall  \\\n",
            "0       lightgbm            0.54  0.891639  0.852014   0.866049  0.838426   \n",
            "1        xgboost            0.59  0.884249  0.832883   0.899741  0.775274   \n",
            "2  random_forest            0.51  0.897797  0.857680   0.889877  0.827731   \n",
            "3       logistic            0.61  0.810516  0.732817   0.770760  0.698434   \n",
            "\n",
            "    roc_auc  \n",
            "0  0.963174  \n",
            "1  0.958142  \n",
            "2  0.962521  \n",
            "3  0.874810  \n",
            "Best model: random_forest threshold: 0.51\n",
            "Saved artifacts to: /content/drive/MyDrive/ds_Hrutik_Adsare\n",
            "Files in csv_files: ['engineered_dataset.csv', 'metrics.csv', 'model_best_random_forest.pkl', 'scaler.pkl', 'best_info.json', 'feature_importance_lightgbm.csv', 'feature_importance_xgboost.csv', 'feature_importance_random_forest.csv', 'classification_report_best.csv']\n",
            "Files in outputs: ['sentiment_time.png', 'pnl_distribution.png', 'trade_size_vs_sentiment.png', 'roc_curve.png', 'precision_recall_curve.png', 'confusion_matrix.png', 'feature_importance_lightgbm.png', 'feature_importance_xgboost.png', 'feature_importance_random_forest.png']\n",
            "Best model: random_forest accuracy: 0.897797252486973\n"
          ]
        }
      ],
      "source": [
        "# ==============================================\n",
        "# Data Science Assignment â€“ Web3 Trading Team\n",
        "# Candidate: Hrutik_Adsare\n",
        "# ==============================================\n",
        "\n",
        "# ----------------------------------------------\n",
        "# 1. Setup / Mount Drive\n",
        "# ----------------------------------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os, json, warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, timezone\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, f1_score, precision_score, recall_score,\n",
        "    roc_auc_score, roc_curve, confusion_matrix, classification_report,\n",
        "    precision_recall_curve, average_precision_score\n",
        ")\n",
        "\n",
        "# Tree libraries\n",
        "import lightgbm as lgb\n",
        "from lightgbm import early_stopping\n",
        "import xgboost as xgb\n",
        "import joblib\n",
        "import seaborn as sns\n",
        "\n",
        "# ----------------------------------------------\n",
        "# 2. Paths & Output Structure\n",
        "# ----------------------------------------------\n",
        "CANDIDATE = \"Hrutik_Adsare\"\n",
        "BASE_DIR = f\"/content/drive/MyDrive/ds_{CANDIDATE}\"\n",
        "os.makedirs(BASE_DIR, exist_ok=True)\n",
        "NOTEBOOKS_DIR = BASE_DIR\n",
        "CSV_DIR = os.path.join(BASE_DIR, \"csv_files\")\n",
        "OUTPUTS_DIR = os.path.join(BASE_DIR, \"outputs\")\n",
        "for d in [CSV_DIR, OUTPUTS_DIR]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "# ----------------------------------------------\n",
        "# 3. Load Datasets\n",
        "# ----------------------------------------------\n",
        "fg = pd.read_csv(\"/content/drive/MyDrive/fear_greed_index.csv\")\n",
        "tr = pd.read_csv(\"/content/drive/MyDrive/historical_data.csv\")\n",
        "print(\"Fear & Greed:\", fg.shape)\n",
        "print(\"Trades:\", tr.shape)\n",
        "\n",
        "# ----------------------------------------------\n",
        "# 4. Clean & Feature Engineering (enhanced)\n",
        "# ----------------------------------------------\n",
        "# --- Sentiment ---\n",
        "fg[\"date\"] = pd.to_datetime(fg[\"date\"], errors=\"coerce\")\n",
        "fg = fg.dropna(subset=[\"date\"]).copy()\n",
        "fg.columns = [c.strip().lower() for c in fg.columns]\n",
        "fg_daily = fg.groupby(\"date\", as_index=False).agg({\"value\": \"last\", \"classification\": \"last\"})\n",
        "\n",
        "sentiment_map = {\"Extreme Fear\": -2, \"Fear\": -1, \"Neutral\": 0, \"Greed\": 1, \"Extreme Greed\": 2}\n",
        "fg_daily[\"sentiment_cat_num\"] = fg_daily[\"classification\"].map(sentiment_map).fillna(0)\n",
        "\n",
        "# create lagged & rolling sentiment features\n",
        "fg_daily = fg_daily.sort_values(\"date\")\n",
        "fg_daily[\"value_lag1\"] = fg_daily[\"value\"].shift(1).fillna(method=\"bfill\")\n",
        "fg_daily[\"value_3d_mean\"] = fg_daily[\"value\"].rolling(3, min_periods=1).mean()\n",
        "fg_daily[\"value_7d_mean\"] = fg_daily[\"value\"].rolling(7, min_periods=1).mean()\n",
        "\n",
        "# --- Trades ---\n",
        "df = tr.copy()\n",
        "df.columns = [c.strip().replace(\" \", \"_\") for c in df.columns]\n",
        "\n",
        "# timestamp parse\n",
        "def to_dt_utc(val):\n",
        "    try:\n",
        "        x = float(val)\n",
        "        if x > 1e12:\n",
        "            x = x / 1000.0\n",
        "        return datetime.fromtimestamp(x, tz=timezone.utc)\n",
        "    except Exception:\n",
        "        try:\n",
        "            dt = datetime.strptime(str(val), \"%d-%m-%Y %H:%M\")\n",
        "            return (dt - pd.Timedelta(hours=5, minutes=30)).replace(tzinfo=timezone.utc)\n",
        "        except Exception:\n",
        "            return pd.NaT\n",
        "\n",
        "ts_candidates = [c for c in df.columns if \"timestamp\" in c.lower()]\n",
        "ts_col = ts_candidates[0] if ts_candidates else None\n",
        "if ts_col is None:\n",
        "    raise RuntimeError(\"No timestamp column detected in trades file.\")\n",
        "df[\"_dt_utc\"] = df[ts_col].apply(to_dt_utc)\n",
        "df = df.dropna(subset=[\"_dt_utc\"]).copy()\n",
        "df[\"_date\"] = pd.to_datetime(df[\"_dt_utc\"].dt.date)\n",
        "\n",
        "# numeric conversions\n",
        "for c in [\"Execution_Price\", \"Size_Tokens\", \"Size_USD\", \"Closed_PnL\", \"Fee\", \"Start_Position\"]:\n",
        "    if c in df.columns:\n",
        "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "# direction\n",
        "if \"Side\" in df.columns:\n",
        "    df[\"is_buy\"] = df[\"Side\"].astype(str).str.upper().eq(\"BUY\").astype(int)\n",
        "else:\n",
        "    df[\"is_buy\"] = 0\n",
        "\n",
        "# per-coin z-score features\n",
        "for c in [\"Execution_Price\", \"Size_USD\"]:\n",
        "    if c in df.columns:\n",
        "        grp = df.groupby(\"Coin\")[c]\n",
        "        df[f\"{c}_z\"] = (df[c] - grp.transform(\"mean\")) / grp.transform(\"std\").replace(0, np.nan)\n",
        "        df[f\"{c}_z\"] = df[f\"{c}_z\"].fillna(0)\n",
        "df[\"log_size_usd\"] = np.log1p(df[\"Size_USD\"].clip(lower=0))\n",
        "\n",
        "# rolling account stats\n",
        "df = df.sort_values([\"Account\", \"_dt_utc\"]).copy()\n",
        "def rolling_stats(g, window=50):\n",
        "    pnl = g[\"Closed_PnL\"].fillna(0)\n",
        "    g[\"roll50_winrate\"] = (pnl > 0).rolling(window, min_periods=5).mean()\n",
        "    g[\"roll50_avg_size_usd\"] = g[\"Size_USD\"].rolling(window, min_periods=5).mean()\n",
        "    g[\"roll50_buy_ratio\"] = g[\"is_buy\"].rolling(window, min_periods=5).mean()\n",
        "    g[\"roll50_pnl_std\"] = pnl.rolling(window, min_periods=5).std().fillna(0)\n",
        "    g[\"roll50_pnl_mean\"] = pnl.rolling(window, min_periods=5).mean().fillna(0)\n",
        "    g[\"inter_trade_sec\"] = g[\"_dt_utc\"].diff().dt.total_seconds().fillna(0)\n",
        "    g[\"roll50_intertrade_mean\"] = g[\"inter_trade_sec\"].rolling(window, min_periods=5).mean().fillna(0)\n",
        "    return g\n",
        "\n",
        "df = df.groupby(\"Account\", group_keys=False).apply(rolling_stats)\n",
        "\n",
        "# merge trades with sentiment\n",
        "feat = df.merge(fg_daily.rename(columns={\"date\": \"_date\"}), on=\"_date\", how=\"left\")\n",
        "for c in [\"value\", \"classification\", \"sentiment_cat_num\", \"value_lag1\", \"value_3d_mean\", \"value_7d_mean\"]:\n",
        "    if c in feat.columns:\n",
        "        feat[c] = feat[c].ffill().bfill()\n",
        "\n",
        "# interaction features\n",
        "feat[\"sentiment_x_size\"] = feat[\"sentiment_cat_num\"] * feat[\"log_size_usd\"]\n",
        "feat[\"sentiment_x_rollwin\"] = feat[\"sentiment_cat_num\"] * feat[\"roll50_winrate\"]\n",
        "\n",
        "# target\n",
        "feat[\"target_profit\"] = (feat[\"Closed_PnL\"] > 0).astype(int)\n",
        "\n",
        "# feature set\n",
        "feature_cols = [c for c in [\n",
        "    \"Execution_Price_z\", \"Size_USD_z\", \"log_size_usd\",\n",
        "    \"roll50_winrate\", \"roll50_avg_size_usd\", \"roll50_buy_ratio\",\n",
        "    \"roll50_pnl_std\", \"roll50_pnl_mean\", \"roll50_intertrade_mean\",\n",
        "    \"is_buy\", \"value\", \"sentiment_cat_num\", \"value_lag1\", \"value_3d_mean\", \"value_7d_mean\",\n",
        "    \"sentiment_x_size\", \"sentiment_x_rollwin\"\n",
        "] if c in feat.columns]\n",
        "\n",
        "dataset = feat[[\"_dt_utc\", \"_date\", \"Account\", \"Coin\", \"Closed_PnL\", \"target_profit\"] + feature_cols].dropna().copy()\n",
        "print(\"Engineered dataset:\", dataset.shape)\n",
        "dataset.to_csv(os.path.join(CSV_DIR, \"engineered_dataset.csv\"), index=False)\n",
        "\n",
        "# ----------------------------------------------\n",
        "# 5. Exploratory visuals\n",
        "# ----------------------------------------------\n",
        "plt.figure(figsize=(10,4))\n",
        "fg_daily.set_index(\"date\")[\"value\"].plot(title=\"Fear & Greed Index Over Time\")\n",
        "plt.ylabel(\"Sentiment Value\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUTS_DIR, \"sentiment_time.png\"))\n",
        "plt.close()\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "sns.histplot(dataset[\"Closed_PnL\"], bins=120)\n",
        "plt.title(\"Closed PnL Distribution\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUTS_DIR, \"pnl_distribution.png\"))\n",
        "plt.close()\n",
        "\n",
        "agg = dataset.groupby(\"_date\").agg({\"log_size_usd\": \"mean\", \"value\": \"mean\"}).reset_index()\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.scatter(agg[\"value\"], agg[\"log_size_usd\"], alpha=0.5, s=8)\n",
        "plt.xlabel(\"Sentiment Value\")\n",
        "plt.ylabel(\"Avg log(Size USD)\")\n",
        "plt.title(\"Avg Trade Size vs Sentiment\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUTS_DIR, \"trade_size_vs_sentiment.png\"))\n",
        "plt.close()\n",
        "\n",
        "# ----------------------------------------------\n",
        "# 6. Time-based split\n",
        "# ----------------------------------------------\n",
        "dataset = dataset.sort_values(\"_dt_utc\")\n",
        "cut = int(len(dataset) * 0.8)\n",
        "train = dataset.iloc[:cut].copy()\n",
        "valid = dataset.iloc[cut:].copy()\n",
        "\n",
        "X_train = train[feature_cols].copy()\n",
        "y_train = train[\"target_profit\"]\n",
        "X_valid = valid[feature_cols].copy()\n",
        "y_valid = valid[\"target_profit\"]\n",
        "\n",
        "print(\"Train / Valid sizes:\", X_train.shape, X_valid.shape)\n",
        "\n",
        "# ----------------------------------------------\n",
        "# 7. Modeling\n",
        "# ----------------------------------------------\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_valid_scaled = scaler.transform(X_valid)\n",
        "\n",
        "# LightGBM\n",
        "lgb_params = {\n",
        "    \"n_estimators\": 1000,\n",
        "    \"learning_rate\": 0.05,\n",
        "    \"num_leaves\": 31,\n",
        "    \"colsample_bytree\": 0.8,\n",
        "    \"subsample\": 0.8,\n",
        "    \"random_state\": 42,\n",
        "    \"n_jobs\": -1,\n",
        "    \"class_weight\": \"balanced\"\n",
        "}\n",
        "lgbm = lgb.LGBMClassifier(**lgb_params)\n",
        "lgbm.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_valid, y_valid)],\n",
        "    eval_metric=\"auc\",\n",
        "    callbacks=[early_stopping(50, verbose=False)]\n",
        ")\n",
        "\n",
        "# XGBoost (<2.0 syntax: early_stopping_rounds)\n",
        "xgb_params = {\n",
        "    \"n_estimators\": 1000,\n",
        "    \"learning_rate\": 0.05,\n",
        "    \"max_depth\": 6,\n",
        "    \"subsample\": 0.8,\n",
        "    \"colsample_bytree\": 0.8,\n",
        "    \"use_label_encoder\": False,\n",
        "    \"eval_metric\": \"auc\",\n",
        "    \"n_jobs\": -1,\n",
        "    \"random_state\": 42,\n",
        "    \"tree_method\": \"hist\",\n",
        "}\n",
        "xgbc = xgb.XGBClassifier(**xgb_params)\n",
        "xgbc.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_valid, y_valid)],\n",
        "    #callbacks=[xgb.callback.EarlyStopping(rounds=50, save_best=True)], # Removed callbacks\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "# RandomForest\n",
        "rf = RandomForestClassifier(n_estimators=400, class_weight=\"balanced\", random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Logistic Regression\n",
        "logit = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", LogisticRegression(max_iter=500, class_weight=\"balanced\"))])\n",
        "logit.fit(X_train, y_train)\n",
        "\n",
        "# ----------------------------------------------\n",
        "# 8. Evaluate & choose best\n",
        "# ----------------------------------------------\n",
        "models = {\"lightgbm\": lgbm, \"xgboost\": xgbc, \"random_forest\": rf, \"logistic\": logit}\n",
        "\n",
        "def get_proba(model, X):\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        return model.predict_proba(X)[:, 1]\n",
        "    return model.decision_function(X)\n",
        "\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    proba = get_proba(model, X_valid)\n",
        "    thresholds = np.linspace(0.01, 0.99, 99)\n",
        "    best_acc, best_t = -1, 0.5\n",
        "    for t in thresholds:\n",
        "        preds = (proba >= t).astype(int)\n",
        "        acc = accuracy_score(y_valid, preds)\n",
        "        if acc > best_acc:\n",
        "            best_acc, best_t = acc, t\n",
        "    preds_best = (proba >= best_t).astype(int)\n",
        "    res = {\n",
        "        \"best_threshold\": float(best_t),\n",
        "        \"accuracy\": float(accuracy_score(y_valid, preds_best)),\n",
        "        \"f1\": float(f1_score(y_valid, preds_best)),\n",
        "        \"precision\": float(precision_score(y_valid, preds_best)),\n",
        "        \"recall\": float(recall_score(y_valid, preds_best)),\n",
        "        \"roc_auc\": float(roc_auc_score(y_valid, proba))\n",
        "    }\n",
        "    results[name] = res\n",
        "\n",
        "metrics_df = pd.DataFrame.from_dict(results, orient=\"index\").reset_index().rename(columns={\"index\": \"model\"})\n",
        "metrics_df.to_csv(os.path.join(CSV_DIR, \"metrics.csv\"), index=False)\n",
        "print(metrics_df)\n",
        "\n",
        "# ----------------------------------------------\n",
        "# 9. Save best model\n",
        "# ----------------------------------------------\n",
        "best_model_name = metrics_df.sort_values(\"accuracy\", ascending=False).iloc[0][\"model\"]\n",
        "best_model = models[best_model_name]\n",
        "best_threshold = results[best_model_name][\"best_threshold\"]\n",
        "print(\"Best model:\", best_model_name, \"threshold:\", best_threshold)\n",
        "\n",
        "joblib.dump(best_model, os.path.join(CSV_DIR, f\"model_best_{best_model_name}.pkl\"))\n",
        "joblib.dump(scaler, os.path.join(CSV_DIR, \"scaler.pkl\"))\n",
        "with open(os.path.join(CSV_DIR, \"best_info.json\"), \"w\") as f:\n",
        "    json.dump({\"best_model\": best_model_name, \"best_threshold\": best_threshold, \"metrics\": results[best_model_name]}, f, indent=2)\n",
        "\n",
        "# ----------------------------------------------\n",
        "# 10. Visuals for the best model\n",
        "# ----------------------------------------------\n",
        "best_proba = get_proba(best_model, X_valid)\n",
        "\n",
        "# ROC\n",
        "fpr, tpr, _ = roc_curve(y_valid, best_proba)\n",
        "auc_score = roc_auc_score(y_valid, best_proba)\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.plot(fpr, tpr, label=f\"ROC (AUC={auc_score:.3f})\")\n",
        "plt.plot([0, 1], [0, 1], \"--\", color=\"gray\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"Validation ROC Curve\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUTS_DIR, \"roc_curve.png\"))\n",
        "plt.close()\n",
        "\n",
        "# Precision-Recall Curve\n",
        "precision, recall, _ = precision_recall_curve(y_valid, best_proba)\n",
        "ap_score = average_precision_score(y_valid, best_proba)\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.plot(recall, precision, label=f\"PR (AP={ap_score:.3f})\")\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUTS_DIR, \"precision_recall_curve.png\"))\n",
        "plt.close()\n",
        "\n",
        "# Confusion matrix\n",
        "best_preds = (best_proba >= best_threshold).astype(int)\n",
        "cm = confusion_matrix(y_valid, best_preds)\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=[\"Loss\",\"Profit\"], yticklabels=[\"Loss\",\"Profit\"])\n",
        "plt.title(f\"Confusion Matrix ({best_model_name})\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUTS_DIR, \"confusion_matrix.png\"))\n",
        "plt.close()\n",
        "\n",
        "# Feature importance\n",
        "def save_feature_importance(model, name):\n",
        "    if hasattr(model, \"feature_importances_\"):\n",
        "        imp = pd.Series(model.feature_importances_, index=feature_cols).sort_values(ascending=False)\n",
        "        imp.to_csv(os.path.join(CSV_DIR, f\"feature_importance_{name}.csv\"))\n",
        "        plt.figure(figsize=(6,6))\n",
        "        imp.head(20).iloc[::-1].plot(kind=\"barh\")\n",
        "        plt.title(f\"Feature Importance ({name})\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(OUTPUTS_DIR, f\"feature_importance_{name}.png\"))\n",
        "        plt.close()\n",
        "\n",
        "for n in [\"lightgbm\", \"xgboost\", \"random_forest\"]:\n",
        "    save_feature_importance(models[n], n)\n",
        "\n",
        "# Classification report\n",
        "report = classification_report(y_valid, best_preds, output_dict=True)\n",
        "pd.DataFrame(report).T.to_csv(os.path.join(CSV_DIR, \"classification_report_best.csv\"))\n",
        "\n",
        "# ----------------------------------------------\n",
        "# 11. Final save & summary\n",
        "# ----------------------------------------------\n",
        "print(\"Saved artifacts to:\", BASE_DIR)\n",
        "print(\"Files in csv_files:\", os.listdir(CSV_DIR)[:20])\n",
        "print(\"Files in outputs:\", os.listdir(OUTPUTS_DIR)[:20])\n",
        "print(\"Best model:\", best_model_name, \"accuracy:\", results[best_model_name][\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjrVh0IkkZ-g"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}